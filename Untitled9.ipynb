{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f589c4d-69dd-419a-b8a0-5e17db629205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights: [0. 0.]\n",
      "Gradient dw: [-0.15       -0.14166667]\n",
      "Updated weights: [0.015      0.01416667]\n",
      "Updated bias: 0.0\n",
      "Loss: 0.6931471785599453\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# نمونه داده‌ خیلی ساده\n",
    "# هر ردیف: [price, area]\n",
    "# y = 0 یا 1\n",
    "# -----------------------------\n",
    "X = np.array([\n",
    "    [200, 70],\n",
    "    [500, 90],\n",
    "    [1500, 200],\n",
    "    [4000, 300]\n",
    "])\n",
    "\n",
    "y = np.array([0, 0, 1, 1])\n",
    "\n",
    "# نرمال‌سازی ساده\n",
    "X = X / np.max(X, axis=0)\n",
    "\n",
    "# تعداد نمونه و ویژگی\n",
    "m, n = X.shape\n",
    "\n",
    "# وزن‌ها\n",
    "w = np.zeros(n)\n",
    "b = 0\n",
    "\n",
    "# -----------------------------\n",
    "# تابع سیگموئید\n",
    "# -----------------------------\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# -----------------------------\n",
    "# محاسبه Cross-Entropy Loss\n",
    "# -----------------------------\n",
    "def loss_fn(y, yhat):\n",
    "    return -np.mean(y * np.log(yhat + 1e-9) + (1 - y) * np.log(1 - yhat + 1e-9))\n",
    "\n",
    "# -----------------------------\n",
    "# Forward pass (Likelihood)\n",
    "# -----------------------------\n",
    "z = X @ w + b\n",
    "yhat = sigmoid(z)\n",
    "\n",
    "# -----------------------------\n",
    "# محاسبه گرادیان‌ها\n",
    "# -----------------------------\n",
    "dz = yhat - y              # (m,)\n",
    "dw = (1/m) * (X.T @ dz)    # (n,)\n",
    "db = (1/m) * np.sum(dz)\n",
    "\n",
    "# -----------------------------\n",
    "# یک بار آپدیت وزن‌ها\n",
    "# -----------------------------\n",
    "lr = 0.1\n",
    "w_new = w - lr * dw\n",
    "b_new = b - lr * db\n",
    "\n",
    "# -----------------------------\n",
    "# پرینت نتایج\n",
    "# -----------------------------\n",
    "print(\"Initial weights:\", w)\n",
    "print(\"Gradient dw:\", dw)\n",
    "print(\"Updated weights:\", w_new)\n",
    "print(\"Updated bias:\", b_new)\n",
    "print(\"Loss:\", loss_fn(y, yhat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9af4a8f4-283b-40f2-bd41-a4ab4e45dd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial W:\n",
      " [[0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "Gradient dW:\n",
      " [[ 0.11        0.07       -0.18      ]\n",
      " [ 0.09555556  0.06888889 -0.16444444]]\n",
      "Updated W:\n",
      " [[-0.011      -0.007       0.018     ]\n",
      " [-0.00955556 -0.00688889  0.01644444]]\n",
      "Loss: 1.0986122856681098\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# داده 3 کلاسه (0,1,2)\n",
    "# -----------------------------\n",
    "X = np.array([\n",
    "    [200, 70],\n",
    "    [500, 90],\n",
    "    [1500, 200],\n",
    "    [2500, 250],\n",
    "    [4000, 300]\n",
    "])\n",
    "\n",
    "y = np.array([0, 0, 1, 2, 2])\n",
    "\n",
    "# نرمال‌سازی\n",
    "X = X / np.max(X, axis=0)\n",
    "\n",
    "m, n = X.shape\n",
    "k = 3   # تعداد کلاس‌ها\n",
    "\n",
    "# تبدیل y به one-hot\n",
    "Y = np.eye(k)[y]  # shape: (m,k)\n",
    "\n",
    "# وزن‌ها\n",
    "W = np.zeros((n, k))\n",
    "b = np.zeros(k)\n",
    "\n",
    "# -----------------------------\n",
    "# Softmax\n",
    "# -----------------------------\n",
    "def softmax(z):\n",
    "    exp_z = np.exp(z - np.max(z))\n",
    "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "# Forward\n",
    "Z = X @ W + b\n",
    "Yhat = softmax(Z)\n",
    "\n",
    "# -----------------------------\n",
    "# Cross-Entropy Loss\n",
    "# -----------------------------\n",
    "loss = -np.mean(np.sum(Y * np.log(Yhat + 1e-9), axis=1))\n",
    "\n",
    "# -----------------------------\n",
    "# Gradient\n",
    "# -----------------------------\n",
    "dZ = (Yhat - Y) / m            # (m,k)\n",
    "dW = X.T @ dZ                  # (n,k)\n",
    "db = np.sum(dZ, axis=0)        # (k,)\n",
    "\n",
    "# -----------------------------\n",
    "# یک بار آپدیت\n",
    "# -----------------------------\n",
    "lr = 0.1\n",
    "W_new = W - lr * dW\n",
    "b_new = b - lr * db\n",
    "\n",
    "print(\"Initial W:\\n\", W)\n",
    "print(\"Gradient dW:\\n\", dW)\n",
    "print(\"Updated W:\\n\", W_new)\n",
    "print(\"Loss:\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c963ec01-9b66-4653-84a1-78ef1d88afd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
